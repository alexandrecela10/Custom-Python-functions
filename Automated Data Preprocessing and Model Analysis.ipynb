{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b165aa9-82a0-4c79-b7ba-e50ccf849852",
   "metadata": {},
   "source": [
    "### Custom automated Encoder. Label Encoding, One Hot Encoding. Can be fit within a pipeline to automate modelling from a untouched training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a51b01-91e3-4e10-9275-708649d25661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45566a9-ebe5-4ec2-a299-2d8fc1cad4fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCategoricalEncoder\u001b[39;00m(\u001b[43mBaseEstimator\u001b[49m, TransformerMixin):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Encodes categorical columns using LabelEncoding, OneHotEncoding and TargetEncoding.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    LabelEncoding is used for binary categorical columns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, lcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, ohecols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, reduce_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    Encodes categorical columns using LabelEncoding, OneHotEncoding and TargetEncoding.\n",
    "    LabelEncoding is used for binary categorical columns\n",
    "    OneHotEncoding is used for columns with <= 10 distinct values\n",
    "    TargetEncoding is used for columns with higher cardinality (>10 distinct values)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols = None, lcols = None, ohecols = None, reduce_df = True):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        cols : list of str\n",
    "            Columns to encode.  Default is to one-hot/target/label encode all categorical columns in the DataFrame.\n",
    "        reduce_df : bool\n",
    "            Whether to use reduced degrees of freedom for encoding\n",
    "            (that is, add N-1 one-hot columns for a column with N \n",
    "            categories). E.g. for a column with categories A, B, \n",
    "            and C: When reduce_df is True, A=[1, 0], B=[0, 1],\n",
    "            and C=[0, 0].  When reduce_df is False, A=[1, 0, 0], \n",
    "            B=[0, 1, 0], and C=[0, 0, 1]\n",
    "            Default = False\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(cols,str):\n",
    "            self.cols = [cols]\n",
    "        else :\n",
    "            self.cols = cols\n",
    "        \n",
    "        if isinstance(lcols,str):\n",
    "            self.lcols = [lcols]\n",
    "        else :\n",
    "            self.lcols = lcols\n",
    "        \n",
    "        if isinstance(ohecols,str):\n",
    "            self.ohecols = [ohecols]\n",
    "        else :\n",
    "            self.ohecols = ohecols\n",
    "        \n",
    "        self.reduce_df = reduce_df\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit label/one-hot/target encoder to X and y\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : encoder\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encode all categorical cols by default\n",
    "        if self.cols is None:\n",
    "            self.cols = [c for c in X if str(X[c].dtype)=='object']\n",
    "\n",
    "        # Check columns are in X\n",
    "        for col in self.cols:\n",
    "            if col not in X:\n",
    "                raise ValueError('Column \\''+col+'\\' not in X')\n",
    "        \n",
    "        # Separating out lcols, ohecols and tcols\n",
    "        if self.lcols is None:\n",
    "            self.lcols = [c for c in self.cols if X[c].nunique() <= 2]\n",
    "        \n",
    "        if self.ohecols is None:\n",
    "            self.ohecols = [c for c in self.cols if ((X[c].nunique() > 2) & (X[c].nunique() <= 10))]\n",
    "        \n",
    "        \n",
    "        ## Create Label Encoding mapping\n",
    "        self.lmaps = dict()\n",
    "        for col in self.lcols:\n",
    "            self.lmaps[col] = dict(zip(X[col].values, X[col].astype('category').cat.codes.values))\n",
    "        \n",
    "        \n",
    "        ## Create OneHot Encoding mapping\n",
    "        self.ohemaps = dict() #dict to store map for each column\n",
    "        for col in self.ohecols:\n",
    "            self.ohemaps[col] = []\n",
    "            uniques = X[col].unique()\n",
    "            for unique in uniques:\n",
    "                self.ohemaps[col].append(unique)\n",
    "            if self.reduce_df:\n",
    "                del self.ohemaps[col][-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Return the fit object\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Perform label/one-hot/target encoding transformation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to label encode\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        \n",
    "        Xo = X.copy()\n",
    "        ## Perform label encoding transformation\n",
    "        for col, lmap in self.lmaps.items():\n",
    "            \n",
    "            # Map the column\n",
    "            Xo[col] = Xo[col].map(lmap)\n",
    "            Xo[col].fillna(-1, inplace=True) ## Filling new values with -1\n",
    "        \n",
    "        \n",
    "        ## Perform one-hot encoding transformation\n",
    "        for col, vals in self.ohemaps.items():\n",
    "            for val in vals:\n",
    "                new_col = col+'_'+str(val)\n",
    "                Xo[new_col] = (Xo[col]==val).astype('uint8')\n",
    "            del Xo[col]\n",
    "        \n",
    "        \n",
    "        ## Return encoded DataFrame\n",
    "        return Xo\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Fit and transform the data via label/one-hot/target encoding.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to encode\n",
    "        y : pandas Series, shape = [n_samples]\n",
    "            Target values (required!).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame\n",
    "            Input DataFrame with transformed columns\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.fit(X, y).transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7073e-a55c-430b-867e-63c4ae4ab172",
   "metadata": {},
   "source": [
    "### Custom Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13670b7d-1d4d-4904-89a0-b0e89c0d256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom standard scaler class with the ability to apply scaling on selected columns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scale_cols = None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        scale_cols : list of str\n",
    "            Columns on which to perform scaling and normalization. Default is to scale all numerical columns\n",
    "        \n",
    "        \"\"\"\n",
    "        self.scale_cols = scale_cols\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        \n",
    "        # Scaling all non-categorical columns if user doesn't provide the list of columns to scale\n",
    "        if self.scale_cols is None:\n",
    "            self.scale_cols = [c for c in X if ((str(X[c].dtype).find('float') != -1) or (str(X[c].dtype).find('int') != -1))]\n",
    "        \n",
    "     \n",
    "        ## Create mapping corresponding to scaling and normalization\n",
    "        self.maps = dict()\n",
    "        for col in self.scale_cols:\n",
    "            self.maps[col] = dict()\n",
    "            self.maps[col]['mean'] = np.mean(X[col].values).round(2)\n",
    "            self.maps[col]['std_dev'] = np.std(X[col].values).round(2)\n",
    "        \n",
    "        # Return fit object\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        Xo = X.copy()\n",
    "        \n",
    "        ## Map transformation to respective columns\n",
    "        for col in self.scale_cols:\n",
    "            Xo[col] = (Xo[col] - self.maps[col]['mean']) / self.maps[col]['std_dev']\n",
    "        \n",
    "        \n",
    "        # Return scaled and normalized DataFrame\n",
    "        return Xo\n",
    "    \n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame, shape [n_samples, n_columns]\n",
    "            DataFrame containing columns to scale\n",
    "        \"\"\"\n",
    "        # Fit and return transformed dataframe\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d4e5c-1a80-49b6-b685-a3aa7003edb1",
   "metadata": {},
   "source": [
    "### Custom Model Analysis. Adaptable to Linear, Logistic Regression, and Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f75afaf-0ab5-4847-be95-00aaf886fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def analyze_model(model, X, y):\n",
    "    if isinstance(model, (LogisticRegression, sm.Logit)):\n",
    "        # Model is logistic or linear regression\n",
    "        if isinstance(model, LogisticRegression):\n",
    "            # Convert scikit-learn logistic regression model to statsmodels format\n",
    "            model = sm.Logit(y, sm.add_constant(X))\n",
    "        result = model.fit()\n",
    "        print(result.summary())\n",
    "        \n",
    "        if isinstance(model, LogisticRegression) or isinstance(model, sm.Logit):\n",
    "            # Perform VIF analysis for both linear and logistic regression models\n",
    "            vif = pd.DataFrame()\n",
    "            vif[\"Variable\"] = X.columns\n",
    "            vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "            print(\"VIF Analysis:\")\n",
    "            print(vif)\n",
    "        \n",
    "        if not isinstance(model, LogisticRegression) and not isinstance(model, sm.Logit):\n",
    "            # Perform residuals analysis only for linear regression models\n",
    "            predictions = result.predict()\n",
    "            residuals = y - predictions\n",
    "            plt.scatter(predictions, residuals)\n",
    "            plt.axhline(y=0, color='r', linestyle='--')\n",
    "            plt.xlabel('Predicted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.title('Residuals Analysis')\n",
    "            plt.show()\n",
    "            \n",
    "    elif isinstance(model, DecisionTreeClassifier):\n",
    "        # Model is a decision tree classifier\n",
    "        importance = model.feature_importances_\n",
    "        print(\"Feature Importance:\")\n",
    "        for feature, importance_score in zip(X.columns, importance):\n",
    "            print(f\"{feature}: {importance_score}\")\n",
    "        \n",
    "        plt.figure(figsize=(18, 12))\n",
    "        plot_tree(model, filled=True, rounded=True, feature_names=X.columns, class_names=True)\n",
    "        plt.title(\"Decision Tree Visualization\")\n",
    "\n",
    "        # Increase font size of text in tree visualization\n",
    "        ax = plt.gca()\n",
    "        for text in ax.texts:\n",
    "            text.set_fontsize(10)  # Adjust the font size as needed\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Model type not supported for analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f77444-fea2-4119-92a9-8a17f4ff6467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
